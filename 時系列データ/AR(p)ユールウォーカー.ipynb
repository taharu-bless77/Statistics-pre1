{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d73026",
   "metadata": {},
   "source": [
    "かしこまりました。m=4、つまりAR(4)モデルの具体的な推定問題を作成します。\n",
    "\n",
    "AR(4)は、例えば「四半期データ」のように、4期前に季節性（1年前の同じ時期）が来るようなデータを分析するのによく使われる、非常に実用的なモデルです。\n",
    "\n",
    "---\n",
    "\n",
    "### 📦 問題設定：ある商品の「四半期ごと」の売上データ\n",
    "\n",
    "* **目的:** 過去の売上データからAR(4)モデルを構築し、来季の予測に役立てたい。\n",
    "* **モデル:** $y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\phi_3 y_{t-3} + \\phi_4 y_{t-4} + \\varepsilon_t$\n",
    "* **推定対象:** 4つのパラメータ $\\phi_1, \\phi_2, \\phi_3, \\phi_4$\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 STEP 1: データから標本自己相関を計算する\n",
    "\n",
    "まず、手元のデータ（例：過去10年分の四半期売上データ、40点）から、標本自己相関 $\\hat{\\rho}_k$ を計算しました。\n",
    "その結果、以下の値が得られたとします。\n",
    "\n",
    "* **ラグ 1 ($\\hat{\\rho}_1$) = 0.6**\n",
    "    * （前期との相関。今期も前期と似た動きをしそう）\n",
    "* **ラグ 2 ($\\hat{\\rho}_2$) = 0.3**\n",
    "    * （2期前との相関。相関が減衰している）\n",
    "* **ラグ 3 ($\\hat{\\rho}_3$) = 0.1**\n",
    "    * （3期前との相関。さらに減衰している）\n",
    "* **ラグ 4 ($\\hat{\\rho}_4$) = 0.7**\n",
    "    * （4期前＝1年前の同じ時期との相関。$\\hat{\\rho}_1$よりも強い相関があり、**強い季節性**が示唆される）\n",
    "\n",
    "---\n",
    "\n",
    "### 📝 STEP 2: ユール＝ウォーカー方程式を立てる (p=4)\n",
    "\n",
    "AR(p)のユール＝ウォーカー方程式 $\\rho_k = \\sum_{i=1}^p \\phi_i \\rho_{k-i}$ に、 $k=1, 2, 3, 4$ を代入し、 $p=4$ の連立方程式を作ります。（ $\\rho_0=1$, $\\rho_{-k}=\\rho_k$ を使います）\n",
    "\n",
    "* **$k=1$**: $\\hat{\\rho}_1 = \\hat{\\phi}_1 \\hat{\\rho}_0 + \\hat{\\phi}_2 \\hat{\\rho}_{-1} + \\hat{\\phi}_3 \\hat{\\rho}_{-2} + \\hat{\\phi}_4 \\hat{\\rho}_{-3}$\n",
    "    * $\\implies \\hat{\\rho}_1 = \\hat{\\phi}_1(1) + \\hat{\\phi}_2 \\hat{\\rho}_1 + \\hat{\\phi}_3 \\hat{\\rho}_2 + \\hat{\\phi}_4 \\hat{\\rho}_3$\n",
    "* **$k=2$**: $\\hat{\\rho}_2 = \\hat{\\phi}_1 \\hat{\\rho}_1 + \\hat{\\phi}_2 \\hat{\\rho}_0 + \\hat{\\phi}_3 \\hat{\\rho}_{-1} + \\hat{\\phi}_4 \\hat{\\rho}_{-2}$\n",
    "    * $\\implies \\hat{\\rho}_2 = \\hat{\\phi}_1 \\hat{\\rho}_1 + \\hat{\\phi}_2(1) + \\hat{\\phi}_3 \\hat{\\rho}_1 + \\hat{\\phi}_4 \\hat{\\rho}_2$\n",
    "* **$k=3$**: $\\hat{\\rho}_3 = \\hat{\\phi}_1 \\hat{\\rho}_2 + \\hat{\\phi}_2 \\hat{\\rho}_1 + \\hat{\\phi}_3 \\hat{\\rho}_0 + \\hat{\\phi}_4 \\hat{\\rho}_{-1}$\n",
    "    * $\\implies \\hat{\\rho}_3 = \\hat{\\phi}_1 \\hat{\\rho}_2 + \\hat{\\phi}_2 \\hat{\\rho}_1 + \\hat{\\phi}_3(1) + \\hat{\\phi}_4 \\hat{\\rho}_1$\n",
    "* **$k=4$**: $\\hat{\\rho}_4 = \\hat{\\phi}_1 \\hat{\\rho}_3 + \\hat{\\phi}_2 \\hat{\\rho}_2 + \\hat{\\phi}_3 \\hat{\\rho}_1 + \\hat{\\phi}_4 \\hat{\\rho}_0$\n",
    "    * $\\implies \\hat{\\rho}_4 = \\hat{\\phi}_1 \\hat{\\rho}_3 + \\hat{\\phi}_2 \\hat{\\rho}_2 + \\hat{\\phi}_3 \\hat{\\rho}_1 + \\hat{\\phi}_4(1)$\n",
    "\n",
    "---\n",
    "\n",
    "### 🧮 STEP 3: 具体的な連立方程式（解くべき問題）\n",
    "\n",
    "STEP 1の具体的な数値 $\\hat{\\rho}_k$ を STEP 2の式に代入します。\n",
    "これが、私たちが解くべき「4元1次連立方程式」です。\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "0.6 = 1.0\\hat{\\phi}_1 + 0.6\\hat{\\phi}_2 + 0.3\\hat{\\phi}_3 + 0.1\\hat{\\phi}_4 \\\\\n",
    "0.3 = 0.6\\hat{\\phi}_1 + 1.0\\hat{\\phi}_2 + 0.6\\hat{\\phi}_3 + 0.3\\hat{\\phi}_4 \\\\\n",
    "0.1 = 0.3\\hat{\\phi}_1 + 0.6\\hat{\\phi}_2 + 1.0\\hat{\\phi}_3 + 0.6\\hat{\\phi}_4 \\\\\n",
    "0.7 = 0.1\\hat{\\phi}_1 + 0.3\\hat{\\phi}_2 + 0.6\\hat{\\phi}_3 + 1.0\\hat{\\phi}_4\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "###  MATRIX: 掃き出し法のための行列表示\n",
    "\n",
    "ご指摘の通り、この問題は「掃き出し法（ガウスの消去法）」で解くことができます。コンピュータで行列演算 $P \\Phi = \\rho$ を解く問題に帰着します。\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & 0.6 & 0.3 & 0.1 \\\\\n",
    "0.6 & 1 & 0.6 & 0.3 \\\\\n",
    "0.3 & 0.6 & 1 & 0.6 \\\\\n",
    "0.1 & 0.3 & 0.6 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} \\hat{\\phi}_1 \\\\ \\hat{\\phi}_2 \\\\ \\hat{\\phi}_3 \\\\ \\hat{\\phi}_4 \\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix} 0.6 \\\\ 0.3 \\\\ 0.1 \\\\ 0.7 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**これが「解くべき具体問題」です。**\n",
    "実務では、統計ソフトがこの行列計算（ $\\Phi = P^{-1} \\rho$ ）を一瞬で実行し、 $\\hat{\\phi}_1, \\dots, \\hat{\\phi}_4$ の値を返してくれます。\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94d287",
   "metadata": {},
   "source": [
    "はい、承知いたしました。\n",
    "AR(p)モデルのユール＝ウォーカー方程式を解くための一般的な手法は、**行列（マトリックス）**を使って非常に簡潔に表現できます。\n",
    "\n",
    "AR(p)モデルのパラメータ $\\phi_1, \\phi_2, \\dots, \\phi_p$ を推定する問題は、以下の $p$ 元連立一次方程式を解く問題に帰着します。\n",
    "\n",
    "$$\n",
    "P \\Phi = \\mathbf{r}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 1. 各ベクトルと行列の定義\n",
    "\n",
    "これが、AR(p)モデルのパラメータをユール＝ウォーカー法（モーメント法）で推定する際の「一般表記」です。\n",
    "\n",
    "* **$\\Phi$ (ファイ): 推定したいパラメータのベクトル ($p \\times 1$)**\n",
    "    私たちが知りたい $p$ 個のパラメータ $\\phi_i$ を縦に並べたベクトルです。\n",
    "    $$\n",
    "    \\Phi = \\begin{pmatrix} \\phi_1 \\\\ \\phi_2 \\\\ \\vdots \\\\ \\phi_p \\end{pmatrix}\n",
    "    $$\n",
    "\n",
    "* **$\\mathbf{r}$ (アール): 既知の自己相関ベクトル ($p \\times 1$)**\n",
    "    データから計算できる（＝既知である）ラグ $1$ から $p$ までの自己相関 $\\rho_k$ を縦に並べたベクトルです。\n",
    "    $$\n",
    "    \\mathbf{r} = \\begin{pmatrix} \\rho_1 \\\\ \\rho_2 \\\\ \\vdots \\\\ \\rho_p \\end{pmatrix}\n",
    "    $$\n",
    "\n",
    "* **$P$ (ピー): 既知の自己相関行列 ($p \\times p$)**\n",
    "    データから計算できる（＝既知である）自己相関 $\\rho_k$ から構築される $p \\times p$ の行列です。 $\\rho_0 = 1$ と $\\rho_{-k} = \\rho_k$ （対称性）のルールに基づいています。\n",
    "    $$\n",
    "    P = \\begin{pmatrix}\n",
    "    \\rho_0 & \\rho_{-1} & \\rho_{-2} & \\dots & \\rho_{-(p-1)} \\\\\n",
    "    \\rho_1 & \\rho_0 & \\rho_{-1} & \\dots & \\rho_{-(p-2)} \\\\\n",
    "    \\rho_2 & \\rho_1 & \\rho_0 & \\dots & \\rho_{-(p-3)} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\rho_{p-1} & \\rho_{p-2} & \\rho_{p-3} & \\dots & \\rho_0\n",
    "    \\end{pmatrix}\n",
    "    $$\n",
    "    これを整理すると、以下のようになります。\n",
    "    $$\n",
    "    P = \\begin{pmatrix}\n",
    "    1 & \\rho_1 & \\rho_2 & \\dots & \\rho_{p-1} \\\\\n",
    "    \\rho_1 & 1 & \\rho_1 & \\dots & \\rho_{p-2} \\\\\n",
    "    \\rho_2 & \\rho_1 & 1 & \\dots & \\rho_{p-3} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\rho_{p-1} & \\rho_{p-2} & \\rho_{p-3} & \\dots & 1\n",
    "    \\end{pmatrix}\n",
    "    $$\n",
    "    この行列 $P$ は、対角成分がすべて 1 、かつ $\\rho_{ij} = \\rho_{ji}$ となる**実対称行列**であり、さらに「対角線に平行な成分がすべて同じ」という性質を持つ**テプリッツ行列 (Toeplitz matrix)** でもあります。\n",
    "\n",
    "---\n",
    "\n",
    "### 2. 実用上の表記（推定値）\n",
    "\n",
    "実務では、理論上の「真の自己相関 $\\rho_k$」は未知です。\n",
    "代わりに、データから計算した「**標本自己相関 $\\hat{\\rho}_k$**」を使います。\n",
    "そのため、推定値（ハット $\\hat{\\ }$ をつける）の表記は以下のようになります。\n",
    "\n",
    "$$\n",
    "\\hat{P} \\hat{\\Phi} = \\hat{\\mathbf{r}}\n",
    "$$\n",
    "\n",
    "* $\\hat{P}$ は $\\hat{\\rho}_k$ で作られた行列\n",
    "* $\\hat{\\mathbf{r}}$ は $\\hat{\\rho}_k$ で作られたベクトル\n",
    "* $\\hat{\\Phi}$ はこれから求めたい推定パラメータ\n",
    "\n",
    "### 3. 解法（掃き出し法）\n",
    "\n",
    "ご指摘の通り、この方程式 $P \\Phi = \\mathbf{r}$ は、$p$ 個の未知数（ $\\phi_1, \\dots, \\phi_p$ ）に対する $p$ 個の連立一次方程式に他なりません。\n",
    "\n",
    "この方程式を解くこと、すなわちパラメータ $\\Phi$ を求めることは、\n",
    "$$\n",
    "\\Phi = P^{-1} \\mathbf{r}\n",
    "$$\n",
    "を計算することと等価です。\n",
    "コンピュータがこの $P^{-1} \\mathbf{r}$ （ $P$ の逆行列と $\\mathbf{r}$ の積）を計算する際、内部では**掃き出し法（ガウスの消去法）**や、 $P$ が正定値対称行列（テプリッツ行列）であることを利用した、より高速で安定した**コレスキー分解**や**レビンソン・ダービン・アルゴリズム**などが使われます。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

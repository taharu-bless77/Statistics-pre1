{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUWcdth_khfN"
      },
      "source": [
        "# 第5回講義 宿題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAjuP7I4lWyn"
      },
      "source": [
        "## 課題\n",
        "\n",
        "今Lessonで学んだことに工夫を加えて，CNNでより高精度なCIFAR10の分類器を実装してみましょう．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpiz19GRlZ_9"
      },
      "source": [
        "### 目標値\n",
        "\n",
        "Accuracy 76%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSHeI_utleEN"
      },
      "source": [
        "### ルール\n",
        "\n",
        "\n",
        "- 訓練データは`x_train`， `t_train`，テストデータは`x_test`で与えられます．\n",
        "- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください．\n",
        "- **下のセルで指定されている`x_train`，`t_train`以外の学習データは使わないでください．**\n",
        "- Pytorchを利用して構いません．\n",
        "- 今回から基本的にAPI制限はありません．\n",
        "- ただしCNNベースでないモデル（Vision Transformerなど）やtorchvision等の既存モデル，学習済みモデルは用いないでください．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diuec-_YluI6"
      },
      "source": [
        "### 提出方法\n",
        "- 2つのファイルを提出していただきます．\n",
        "    1. テストデータ (`x_test`) に対する予測ラベルをcsv形式で保存し，**Omnicampusの宿題タブから「第5回 畳み込みニューラルネットワーク」を選択して**提出してください．\n",
        "    2. それに対応するpythonのコードを　ファイル＞ダウンロード＞.pyをダウンロード　から保存し，**Omnicampusの宿題タブから「第5回 畳み込みニューラルネットワーク (code)」を選択して**提出してください．pythonファイル自体の提出ではなく，「提出内容」の部分にコード全体をコピー&ペーストしてください．\n",
        "      \n",
        "- なお，採点は1で行い，2はコードの確認用として利用します（成績優秀者はコード内容を公開させていただくかもしれません）．コードの内容を変更した場合は，**1と2の両方を提出し直してください**．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hofSzJsVlvKp"
      },
      "source": [
        "### 評価方法\n",
        "\n",
        "- 予測ラベルの`t_test`に対する精度 (Accuracy) で評価します．\n",
        "- 即時採点しLeader Boardを更新します（採点スケジュールは別アナウンス）．\n",
        "- 締切時の点数を最終的な評価とします．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ドライブのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8dS-Kfw6fBxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 作業ディレクトリを指定\n",
        "work_dir = 'drive/MyDrive/Colab Notebooks' # ご自身の環境に合わせて修正してください"
      ],
      "metadata": {
        "id": "jZI4dfoQdaRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu4cmQtelx19"
      },
      "source": [
        "### データの読み込み（この部分は修正しないでください）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsLDDSUJkRx-"
      },
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#学習データ\n",
        "x_train = np.load(work_dir +  '/第5回/data/x_train.npy')\n",
        "t_train = np.load(work_dir +  '/第5回/data/_train.npy')\n",
        "\n",
        "#テストデータ\n",
        "x_test = np.load(work_dir +  '/第5回/data/x_test.npy')\n",
        "\n",
        "class train_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_train, t_train):\n",
        "        data = x_train.astype('float32')\n",
        "        self.x_train = []\n",
        "        for i in range(data.shape[0]):\n",
        "            self.x_train.append(Image.fromarray(np.uint8(data[i])))\n",
        "        self.t_train = t_train\n",
        "        self.transform = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.x_train[idx]), torch.tensor(t_train[idx], dtype=torch.long)\n",
        "\n",
        "class test_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_test):\n",
        "        data = x_test.astype('float32')\n",
        "        self.x_test = []\n",
        "        for i in range(data.shape[0]):\n",
        "            self.x_test.append(Image.fromarray(np.uint8(data[i])))\n",
        "        self.transform = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_test)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.x_test[idx])\n",
        "\n",
        "trainval_data = train_dataset(x_train, t_train)\n",
        "test_data = test_dataset(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrSpHDIWOfK_"
      },
      "source": [
        "### 畳み込みニューラルネットワーク(CNN)の実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKAe0F36nSvU"
      },
      "source": [
        "def fix_seed(seed=1234):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "fix_seed(seed=42)\n",
        "\n",
        "\n",
        "class gcn():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, x):\n",
        "        mean = torch.mean(x)\n",
        "        std = torch.std(x)\n",
        "        return (x - mean)/(std + 10**(-6))  # 0除算を防ぐ\n",
        "\n",
        "\n",
        "class ZCAWhitening():\n",
        "    def __init__(self, epsilon=1e-4, device=\"cuda\"):  # 計算が重いのでGPUを用いる\n",
        "        self.epsilon = epsilon\n",
        "        self.device = device\n",
        "\n",
        "    def fit(self, images):  # 変換行列と平均をデータから計算\n",
        "        x = images[0][0].reshape(1, -1)\n",
        "        self.mean = torch.zeros([1, x.size()[1]]).to(self.device)\n",
        "        con_matrix = torch.zeros([x.size()[1], x.size()[1]]).to(self.device)\n",
        "        for i in range(len(images)):  # 各データについての平均を取る\n",
        "            x = images[i][0].reshape(1, -1).to(self.device)\n",
        "            self.mean += x / len(images)\n",
        "            con_matrix += torch.mm(x.t(), x) / len(images)\n",
        "            if i % 10000 == 0:\n",
        "                print(\"{0}/{1}\".format(i, len(images)))\n",
        "        con_matrix -= torch.mm(self.mean.t(), self.mean)\n",
        "        self.E, self.V = torch.linalg.eigh(con_matrix)  # 固有値分解\n",
        "        self.E = torch.max(self.E, torch.zeros_like(self.E)) # 誤差の影響で負になるのを防ぐ\n",
        "        self.ZCA_matrix = torch.mm(torch.mm(self.V, torch.diag((self.E.squeeze()+self.epsilon)**(-0.5))), self.V.t())\n",
        "        print(\"completed!\")\n",
        "\n",
        "    def __call__(self, x):\n",
        "        size = x.size()\n",
        "        x = x.reshape(1, -1).to(self.device)\n",
        "        x -= self.mean\n",
        "        x = torch.mm(x, self.ZCA_matrix.t())\n",
        "        x = x.reshape(tuple(size))\n",
        "        x = x.to(\"cpu\")\n",
        "        return x\n",
        "\n",
        "\n",
        "# (datasetのクラスを自作したので，このあたりの処理が少し変わっています)\n",
        "\n",
        "zca = ZCAWhitening()\n",
        "zca.fit(trainval_data)\n",
        "\n",
        "val_size = 3000\n",
        "train_data, val_data = torch.utils.data.random_split(trainval_data, [len(trainval_data)-val_size, val_size])  # 訓練データと検証データに分割\n",
        "\n",
        "\n",
        "# 前処理を定義\n",
        "# CNN: データ拡張 (Data Augmentation) と正規化 (Normalization) の定義\n",
        "# 訓練データには、過学習を防ぐためにランダムな変換（水平反転、クロップ）を適用\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # データ拡張: ランダムに水平反転\n",
        "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),  # データ拡張: 4ピクセルパディング後、ランダムに32x32をクロップ\n",
        "    transforms.ToTensor(),  # PIL Image を Tensor (C, H, W) に変換 [0, 255] -> [0.0, 1.0]\n",
        "    zca  # ZCA Whitening (前処理) を適用\n",
        "])\n",
        "\n",
        "# 検証・テストデータにはデータ拡張を行わず、ToTensorとZCAのみ適用\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # PIL Image を Tensor (C, H, W) に変換\n",
        "    zca  # ZCA Whitening (前処理) を適用\n",
        "])\n",
        "\n",
        "# データセットに前処理を設定\n",
        "trainval_data.transform = transform_train\n",
        "test_data.transform = transform\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# CNN: データローダーの定義 (バッチ処理、シャッフル)\n",
        "dataloader_train = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "dataloader_valid = torch.utils.data.DataLoader(\n",
        "    val_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PADQiKNa2snb"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "rng = np.random.RandomState(1234)\n",
        "random_state = 42\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# CNN: モデルアーキテクチャの定義\n",
        "class Cifar10CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Cifar10CNN, self).__init__()\n",
        "        \n",
        "        # --- CNN: 特徴抽出ブロック 1 ---\n",
        "        # (Input: 3x32x32, Output: 64x32x32)\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64) # バッチ正規化\n",
        "        # (Input: 64x32x32, Output: 64x32x32)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        # (Input: 64x32x32, Output: 64x16x16)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # プーリング層\n",
        "        self.dropout1 = nn.Dropout2d(p=0.25) # Dropout (過学習防止)\n",
        "\n",
        "        # --- CNN: 特徴抽出ブロック 2 ---\n",
        "        # (Input: 64x16x16, Output: 128x16x16)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        # (Input: 128x16x16, Output: 128x16x16)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        # (Input: 128x16x16, Output: 128x8x8)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout2 = nn.Dropout2d(p=0.25)\n",
        "\n",
        "        # --- CNN: 分類器 (全結合層) ---\n",
        "        # 特徴抽出ブロックの出力サイズ: 128チャンネル * 8ピクセル * 8ピクセル\n",
        "        self.fc_input_features = 128 * 8 * 8\n",
        "        \n",
        "        # (Input: 128*8*8, Output: 512)\n",
        "        self.fc1 = nn.Linear(self.fc_input_features, 512)\n",
        "        self.bn_fc1 = nn.BatchNorm1d(512) # 1Dのバッチ正規化\n",
        "        self.dropout_fc = nn.Dropout(p=0.5) # Dropout\n",
        "        \n",
        "        # (Input: 512, Output: 10)\n",
        "        self.fc2 = nn.Linear(512, num_classes) # 出力層 (10クラス)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN: 順伝播 (Forward) の定義\n",
        "        \n",
        "        # --- ブロック 1 --- (畳み込み -> 正規化 -> 活性化) x 2 -> プーリング -> Dropout\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # --- ブロック 2 --- (畳み込み -> 正規化 -> 活性化) x 2 -> プーリング -> Dropout\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # --- 分類器 ---\n",
        "        # CNN: 平坦化 (Flatten) - (N, C, H, W) を (N, C*H*W) に変形\n",
        "        x = x.view(-1, self.fc_input_features) \n",
        "        \n",
        "        # (全結合 -> 正規化 -> 活性化 -> Dropout)\n",
        "        x = F.relu(self.bn_fc1(self.fc1(x)))\n",
        "        x = self.dropout_fc(x)\n",
        "        \n",
        "        # (出力層)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "conv_net = Cifar10CNN().to(device)\n",
        "\n",
        "\n",
        "def init_weights(m):  # Heの初期化\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "        torch.nn.init.kaiming_normal_(m.weight)\n",
        "        m.bias.data.fill_(0.0)\n",
        "\n",
        "\n",
        "conv_net.apply(init_weights)\n",
        "\n",
        "\n",
        "n_epochs = 5\n",
        "lr = 0.01\n",
        "device = 'cuda'\n",
        "\n",
        "conv_net.to(device)\n",
        "# CNN: 最適化手法の定義 (Adam: 学習率 lr)\n",
        "optimizer = optim.Adam(conv_net.parameters(), lr=lr)\n",
        "\n",
        "# CNN: 損失関数の定義 (多クラス分類のためのクロスエントロピー)\n",
        "loss_function = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlOZuLu-328i"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    losses_train = []\n",
        "    losses_valid = []\n",
        "\n",
        "    # CNN: モデルを訓練 (Train) モードに設定 (Dropout, BatchNormを有効化)\n",
        "    conv_net.train()\n",
        "    n_train = 0\n",
        "    acc_train = 0\n",
        "    for x, t in dataloader_train:\n",
        "        # --- 訓練フェーズ --- \n",
        "        n_train += len(t) # 処理したデータ数を加算\n",
        "\n",
        "        # データをGPU/CPUに転送\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # CNN: 勾配の初期化 (前回のバッチの勾配をリセット)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # CNN: 順伝播 (Forward) - モデルで予測\n",
        "        y = conv_net.forward(x)\n",
        "\n",
        "        # CNN: 損失 (Loss) の計算 (予測 y と正解 t の誤差)\n",
        "        loss = loss_function(y, t)\n",
        "\n",
        "        # CNN: 逆伝播 (Backward) - 損失に基づいて勾配を計算\n",
        "        loss.backward()\n",
        "\n",
        "        # CNN: パラメータの更新 - 勾配に基づいて重みを更新\n",
        "        optimizer.step()\n",
        "\n",
        "        # 予測結果の取得 (最も確率の高いクラス)\n",
        "        pred = y.argmax(1)\n",
        "        # --- 訓練フェーズ終了 --- \n",
        "\n",
        "        acc_train += (pred == t).float().sum().item()\n",
        "        losses_train.append(loss.tolist())\n",
        "\n",
        "    # CNN: モデルを評価 (Evaluation) モードに設定 (Dropout, BatchNormを無効化)\n",
        "    conv_net.eval()\n",
        "    n_val = 0\n",
        "    acc_val = 0\n",
        "    for x, t in dataloader_valid:\n",
        "        # --- 検証フェーズ --- \n",
        "        n_val += len(t) # 処理したデータ数を加算\n",
        "\n",
        "        # データをGPU/CPUに転送\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # CNN: 順伝播 (Forward)\n",
        "        # torch.no_grad() ブロックで勾配計算を無効にし、メモリ効率化・高速化\n",
        "        with torch.no_grad():\n",
        "            y = conv_net.forward(x)\n",
        "\n",
        "        # CNN: 損失 (Loss) の計算\n",
        "        loss = loss_function(y, t)\n",
        "\n",
        "        # 予測結果の取得\n",
        "        pred = y.argmax(1)\n",
        "        # --- 検証フェーズ終了 --- \n",
        "\n",
        "        acc_val += (pred == t).float().sum().item()\n",
        "        losses_valid.append(loss.tolist())\n",
        "\n",
        "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n",
        "        epoch,\n",
        "        np.mean(losses_train),\n",
        "        acc_train/n_train,\n",
        "        np.mean(losses_valid),\n",
        "        acc_val/n_val\n",
        "    ))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq3scS5j4Rt2"
      },
      "source": [
        "conv_net.eval()\n",
        "\n",
        "t_pred = []\n",
        "for x in dataloader_test:\n",
        "\n",
        "    x = x.to(device)\n",
        "\n",
        "    # CNN: 順伝播 (Forward) - テストデータで予測\n",
        "    # 勾配計算は不要\n",
        "    with torch.no_grad():\n",
        "        y = conv_net.forward(x)\n",
        "\n",
        "    # モデルの出力を予測値のスカラーに変換\n",
        "    pred = y.argmax(1).tolist()\n",
        "\n",
        "    t_pred.extend(pred)\n",
        "\n",
        "submission = pd.Series(t_pred, name='label')\n",
        "submission.to_csv(work_dir + '/第5回/submission_pred_05.csv', header=True, index_label='id')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}